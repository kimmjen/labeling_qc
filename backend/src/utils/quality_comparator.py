#!/usr/bin/env python3
"""
ê²€ìˆ˜ ë¹„êµ ë„êµ¬ - ìžë™ ê²€ìˆ˜ ê²°ê³¼ì™€ ìˆ˜ë™ ê²€ìˆ˜ ê²°ê³¼ë¥¼ ë¹„êµ
"""

import json
from pathlib import Path
from typing import Dict, List, Any
from dataclasses import dataclass

from backend.src.core import QualityController
from backend.src.models.quality_issue import QualityIssue
from backend.src.utils.zip_processor import ZipProcessor


@dataclass
class ComparisonResult:
    """ë¹„êµ ê²°ê³¼ ë°ì´í„° í´ëž˜ìŠ¤"""
    file_path: str
    auto_issues: List[QualityIssue]
    manual_fixed: bool
    differences: List[str]
    accuracy_score: float


class QualityComparator:
    """í’ˆì§ˆ ê²€ìˆ˜ ë¹„êµê¸°"""
    
    def __init__(self):
        self.controller = QualityController()
        self.zip_processor = ZipProcessor()
    
    def compare_directories(self, target_dir: Path, completed_dir: Path) -> List[ComparisonResult]:
        """í´ë”ëª… ë§¤ì¹­ + visualinfo/*.jsonë§Œ ë¹„êµ"""
        results = []
        
        # ë¨¼ì € ê° ë””ë ‰í† ë¦¬ì—ì„œ ZIP íŒŒì¼ ì²˜ë¦¬
        print(f"ðŸ” ì›ë³¸ í´ë” ZIP ì²˜ë¦¬ ì¤‘: {target_dir}")
        target_jsons = self._get_json_files(target_dir, "ì›ë³¸")
        
        print(f"ðŸ” ë¹„êµ í´ë” ZIP ì²˜ë¦¬ ì¤‘: {completed_dir}")
        completed_jsons = self._get_json_files(completed_dir, "ë¹„êµ")
        
        # visualinfo/*.json íŒŒì¼ë“¤ì˜ ID ì¶”ì¶œ ë° ë§¤ì¹­
        target_jsons_by_id = {}
        completed_jsons_by_id = {}
        
        for json_file in target_jsons:
            if "visualinfo" in str(json_file):
                doc_id = self._get_file_key(json_file)
                if doc_id:
                    target_jsons_by_id[doc_id] = json_file
        
        for json_file in completed_jsons:
            if "visualinfo" in str(json_file):
                doc_id = self._get_file_key(json_file)
                if doc_id:
                    completed_jsons_by_id[doc_id] = json_file
        
        total_docs = len(set(target_jsons_by_id.keys()) | set(completed_jsons_by_id.keys()))
        print(f"\nðŸ“Š ì´ {total_docs}ê°œ ë¬¸ì„œ ë°œê²¬")
        print(f"ðŸ“„ ì›ë³¸: {len(target_jsons_by_id)}ê°œ")
        print(f"ðŸ“„ ë¹„êµ: {len(completed_jsons_by_id)}ê°œ")
        
        # ë§¤ì¹­ë˜ëŠ” íŒŒì¼ë“¤ì„ ë¹„êµ
        compared = 0
        for doc_id, target_json in sorted(target_jsons_by_id.items()):
            if doc_id in completed_jsons_by_id:
                completed_json = completed_jsons_by_id[doc_id]
                result = self._compare_single_file(target_json, completed_json)
                results.append(result)
                compared += 1
                print(f"âœ… ë¹„êµ ì™„ë£Œ ({compared}/{total_docs}): {doc_id}")
            else:
                print(f"âš ï¸ ì •ë‹µ íŒŒì¼ ì—†ìŒ: {doc_id}")
        
        # ë¹„êµë˜ì§€ ì•Šì€ ì •ë‹µ íŒŒì¼ ì²´í¬
        missing = 0
        for doc_id in sorted(completed_jsons_by_id.keys()):
            if doc_id not in target_jsons_by_id:
                missing += 1
                print(f"âš ï¸ ì›ë³¸ íŒŒì¼ ì—†ìŒ: {doc_id}")
        
        if missing > 0:
            print(f"\nâš ï¸ {missing}ê°œ íŒŒì¼ì´ ì›ë³¸ì—ì„œ ëˆ„ë½ë¨")
        
        return results
    
    def _get_json_files(self, directory: Path, label: str) -> List[Path]:
        """ë””ë ‰í† ë¦¬ì—ì„œ JSON íŒŒì¼ ì¶”ì¶œ - ìžë™ìœ¼ë¡œ ZIP ì²˜ë¦¬"""
        # ZIP íŒŒì¼ ì²˜ë¦¬
        zip_files = list(directory.rglob("*.zip"))
        if zip_files:
            print(f"ï¿½ {label} ë””ë ‰í† ë¦¬ì—ì„œ ZIP íŒŒì¼ {len(zip_files)}ê°œ ë°œê²¬, ì••ì¶• í•´ì œ ì‹œìž‘...")
            for zip_file in zip_files:
                self.zip_processor.extract_zip_file(zip_file)
        
        # visualinfo/*.json íŒŒì¼ë§Œ ê²€ìƒ‰
        json_files = list(directory.rglob("visualinfo/*.json"))
        print(f"ðŸ“„ {label} ë””ë ‰í† ë¦¬ì—ì„œ visualinfo JSON íŒŒì¼ {len(json_files)}ê°œ ë°œê²¬")
        
        return json_files
    
    def _get_file_key(self, file_path: Path) -> str:
        """íŒŒì¼ ë§¤ì¹­ìš© í‚¤ ìƒì„±"""
        # visualinfo íŒŒì¼ëª…ì—ì„œ ê³ ìœ  ì‹ë³„ìž ì¶”ì¶œ
        name = file_path.name
        if "_visualinfo" in name:
            # "FLAW2023000592_visualinfo.json" â†’ "FLAW2023000592"
            return name.split("_visualinfo")[0]
        else:
            return file_path.stem
            
    def _get_folder_name(self, file_path: Path) -> str:
        """íŒŒì¼ ê²½ë¡œì—ì„œ ìƒìœ„ í´ë”ëª… ì¶”ì¶œ"""
        # visualinfo/*.json íŒŒì¼ì˜ ìƒìœ„ í´ë”ëª… ì¶”ì¶œ
        try:
            # visualinfoì˜ ìƒìœ„ í´ë”ëª…ì´ ì‹¤ì œ ë¬¸ì„œ ID
            return file_path.parent.parent.name
        except:
            return ""
    
    def _compare_single_file(self, target_file: Path, completed_file: Path) -> ComparisonResult:
        """ë‹¨ì¼ íŒŒì¼ ë¹„êµ"""
        # ìžë™ ê²€ìˆ˜ ì‹¤í–‰
        auto_issues = self.controller.validate_file(target_file)
        
        # ì›ë³¸ê³¼ ê²€ìˆ˜ì™„ë£Œ íŒŒì¼ ë¹„êµ
        differences = self._find_differences(target_file, completed_file)
        
        # ì •í™•ë„ ê³„ì‚°
        accuracy = self._calculate_accuracy(auto_issues, differences)
        
        return ComparisonResult(
            file_path=str(target_file.name),
            auto_issues=auto_issues,
            manual_fixed=len(differences) > 0,
            differences=differences,
            accuracy_score=accuracy
        )
    
    def _find_differences(self, target_file: Path, completed_file: Path) -> List[str]:
        """íŒŒì¼ ê°„ ì°¨ì´ì  ì°¾ê¸°"""
        differences = []
        
        try:
            with open(target_file, 'r', encoding='utf-8') as f:
                target_data = json.load(f)
            
            with open(completed_file, 'r', encoding='utf-8') as f:
                completed_data = json.load(f)
            
            # ìš”ì†Œë³„ ë¹„êµ
            target_elements = {e.get('id'): e for e in target_data.get('elements', [])}
            completed_elements = {e.get('id'): e for e in completed_data.get('elements', [])}
            
            # ë¼ë²¨ ë³€ê²½ í™•ì¸
            for element_id, target_element in target_elements.items():
                if element_id in completed_elements:
                    completed_element = completed_elements[element_id]
                    
                    target_label = target_element.get('category', {}).get('label', '')
                    completed_label = completed_element.get('category', {}).get('label', '')
                    
                    if target_label != completed_label:
                        text = target_element.get('content', {}).get('text', '')[:30]
                        differences.append(f"ë¼ë²¨ ë³€ê²½: {element_id} '{text}...' {target_label} â†’ {completed_label}")
            
            # ìš”ì†Œ ì¶”ê°€/ì œê±° í™•ì¸
            added_elements = set(completed_elements.keys()) - set(target_elements.keys())
            removed_elements = set(target_elements.keys()) - set(completed_elements.keys())
            
            for element_id in added_elements:
                differences.append(f"ìš”ì†Œ ì¶”ê°€: {element_id}")
            
            for element_id in removed_elements:
                differences.append(f"ìš”ì†Œ ì œê±°: {element_id}")
        
        except Exception as e:
            differences.append(f"íŒŒì¼ ë¹„êµ ì˜¤ë¥˜: {str(e)}")
        
        return differences
    
    def _calculate_accuracy(self, auto_issues: List[QualityIssue], manual_differences: List[str]) -> float:
        """ì •í™•ë„ ê³„ì‚°"""
        if not manual_differences:
            # ìˆ˜ë™ ìˆ˜ì •ì´ ì—†ê³  ìžë™ ê²€ìˆ˜ì—ì„œë„ ì´ìŠˆê°€ ì—†ìœ¼ë©´ 100%
            return 100.0 if not auto_issues else 90.0
        
        # ìžë™ ê²€ìˆ˜ê°€ ë°œê²¬í•œ ì´ìŠˆì™€ ìˆ˜ë™ ìˆ˜ì •ì´ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ ê³„ì‚°
        auto_label_issues = [issue for issue in auto_issues if 'label' in issue.message.lower()]
        manual_label_changes = [diff for diff in manual_differences if 'ë¼ë²¨ ë³€ê²½' in diff]
        
        if not auto_label_issues and not manual_label_changes:
            return 100.0
        
        if not auto_label_issues:
            return 50.0  # ìžë™ ê²€ìˆ˜ê°€ ë†“ì¹œ ê²½ìš°
        
        if not manual_label_changes:
            return 70.0  # ìžë™ ê²€ìˆ˜ê°€ ê³¼ê²€ì¶œí•œ ê²½ìš°
        
        # ê°„ë‹¨í•œ ì¼ì¹˜ë„ ê³„ì‚°
        match_ratio = min(len(auto_label_issues), len(manual_label_changes)) / max(len(auto_label_issues), len(manual_label_changes))
        return match_ratio * 100
    
    def generate_comparison_report(self, results: List[ComparisonResult]) -> Dict[str, Any]:
        """ë¹„êµ ë³´ê³ ì„œ ìƒì„±"""
        total_files = len(results)
        files_with_manual_fixes = sum(1 for r in results if r.manual_fixed)
        
        # ì •í™•ë„ í†µê³„
        accuracies = [r.accuracy_score for r in results]
        avg_accuracy = sum(accuracies) / len(accuracies) if accuracies else 0
        
        # ì´ìŠˆ í†µê³„
        total_auto_issues = sum(len(r.auto_issues) for r in results)
        total_manual_changes = sum(len(r.differences) for r in results)
        
        # ê°€ìž¥ ë§Žì€ ì´ìŠˆê°€ ìžˆëŠ” íŒŒì¼ë“¤
        top_issue_files = sorted(results, key=lambda r: len(r.auto_issues), reverse=True)[:5]
        
        return {
            "summary": {
                "total_files": total_files,
                "files_with_manual_fixes": files_with_manual_fixes,
                "manual_fix_rate": (files_with_manual_fixes / total_files * 100) if total_files > 0 else 0,
                "average_accuracy": avg_accuracy,
                "total_auto_issues": total_auto_issues,
                "total_manual_changes": total_manual_changes
            },
            "accuracy_distribution": {
                "high_accuracy": sum(1 for a in accuracies if a >= 80),
                "medium_accuracy": sum(1 for a in accuracies if 60 <= a < 80),
                "low_accuracy": sum(1 for a in accuracies if a < 60)
            },
            "top_issue_files": [
                {
                    "file": r.file_path,
                    "auto_issues_count": len(r.auto_issues),
                    "manual_changes_count": len(r.differences),
                    "accuracy": r.accuracy_score
                }
                for r in top_issue_files
            ],
            "detailed_results": [
                {
                    "file": r.file_path,
                    "auto_issues": [issue.to_dict() for issue in r.auto_issues],
                    "manual_differences": r.differences,
                    "accuracy_score": r.accuracy_score
                }
                for r in results
            ]
        }
    
    def print_summary(self, report: Dict[str, Any]):
        """ìš”ì•½ ì¶œë ¥"""
        summary = report["summary"]
        
        print("\n" + "="*60)
        print("ðŸ“Š ê²€ìˆ˜ ë¹„êµ ê²°ê³¼ ìš”ì•½")
        print("="*60)
        
        print(f"ðŸ“ ì´ ë¹„êµ íŒŒì¼ ìˆ˜: {summary['total_files']}ê°œ")
        print(f"ðŸ”§ ìˆ˜ë™ ìˆ˜ì • íŒŒì¼ ìˆ˜: {summary['files_with_manual_fixes']}ê°œ ({summary['manual_fix_rate']:.1f}%)")
        print(f"ðŸŽ¯ í‰ê·  ì •í™•ë„: {summary['average_accuracy']:.1f}%")
        print(f"ðŸ” ìžë™ ê²€ì¶œ ì´ìŠˆ: {summary['total_auto_issues']}ê°œ")
        print(f"âœï¸ ìˆ˜ë™ ìˆ˜ì • ì‚¬í•­: {summary['total_manual_changes']}ê°œ")
        
        print(f"\nðŸ“ˆ ì •í™•ë„ ë¶„í¬:")
        acc_dist = report["accuracy_distribution"]
        print(f"  ë†’ìŒ (80% ì´ìƒ): {acc_dist['high_accuracy']}ê°œ")
        print(f"  ë³´í†µ (60-79%): {acc_dist['medium_accuracy']}ê°œ")
        print(f"  ë‚®ìŒ (60% ë¯¸ë§Œ): {acc_dist['low_accuracy']}ê°œ")
        
        print(f"\nðŸ”¥ ì´ìŠˆê°€ ë§Žì€ ìƒìœ„ íŒŒì¼:")
        for i, file_info in enumerate(report["top_issue_files"][:3], 1):
            print(f"  {i}. {Path(file_info['file']).name}")
            print(f"     ìžë™ê²€ì¶œ: {file_info['auto_issues_count']}ê°œ, ìˆ˜ë™ìˆ˜ì •: {file_info['manual_changes_count']}ê°œ")
            print(f"     ì •í™•ë„: {file_info['accuracy']:.1f}%")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    parser = argparse.ArgumentParser(description="ìžë™ìˆ˜ì • ê²°ê³¼ì™€ ì •ë‹µ í´ë” ë¹„êµ")
    parser.add_argument("target_dir", help="ìžë™ìˆ˜ì • ê²°ê³¼ í´ë” ê²½ë¡œ")
    parser.add_argument("completed_dir", help="ì •ë‹µ(ìˆ˜ë™ê²€ìˆ˜) í´ë” ê²½ë¡œ")
    parser.add_argument("--report", help="ë¹„êµ ë¦¬í¬íŠ¸ ì €ìž¥ ê²½ë¡œ", default="quality_comparison_report.json")
    args = parser.parse_args()

    target_dir = Path(args.target_dir)
    completed_dir = Path(args.completed_dir)
    report_file = Path(args.report)

    if not target_dir.exists():
        print(f"âŒ ê²€ìˆ˜ ëŒ€ìƒ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {target_dir}")
        return

    if not completed_dir.exists():
        print(f"âŒ ê²€ìˆ˜ ì™„ë£Œ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {completed_dir}")
        return

    print("ðŸš€ ê²€ìˆ˜ ë¹„êµ ì‹œìž‘")
    print(f"ðŸ“‚ ê²€ìˆ˜ ëŒ€ìƒ: {target_dir}")
    print(f"ðŸ“‚ ê²€ìˆ˜ ì™„ë£Œ: {completed_dir}")

    # ë¹„êµ ì‹¤í–‰
    comparator = QualityComparator()
    results = comparator.compare_directories(target_dir, completed_dir)

    # ë³´ê³ ì„œ ìƒì„±
    report = comparator.generate_comparison_report(results)

    # ê²°ê³¼ ì¶œë ¥
    comparator.print_summary(report)

    # ìƒì„¸ ë³´ê³ ì„œ ì €ìž¥
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"\nðŸ’¾ ìƒì„¸ ë³´ê³ ì„œ ì €ìž¥: {report_file}")


if __name__ == "__main__":
    main()
